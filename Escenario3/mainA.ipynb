{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementación Red Neuronal con CUDA\n",
        "## Luis Miguel Henao y Mariana López"
      ],
      "metadata": {
        "id": "NcFDCnAFCBpT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importación de librerías"
      ],
      "metadata": {
        "id": "ljhjdD3_CUbA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7gu_sN0B52s",
        "outputId": "e3b5cb3d-0194-4f93-a902-5cca17198636"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mainA.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile mainA.cu\n",
        "#include <stdio.h>  // Leer y escribir en consola\n",
        "#include <stdlib.h> // Funciones generales de utilidad\n",
        "#include <math.h>   // Funciones matemáticas\n",
        "#include <time.h>   // Medición de tiempo\n",
        "#include <string.h> // Manipulación de cadenas\n",
        "#include <cuda_runtime.h> // Librería para CUDA\n",
        "#pragma region Clases y Estructuras\n",
        "\n",
        "typedef struct\n",
        "{\n",
        "    int filas;\n",
        "    int columnas;\n",
        "    float *datos; // Puntero a los datos de la matriz en una sola dimensión\n",
        "} Matriz;\n",
        "\n",
        "// Crear una matriz con dimensiones dadas y reservar memoria\n",
        "Matriz *crear_matriz(int filas, int columnas)\n",
        "{\n",
        "    Matriz *m = (Matriz *)malloc(sizeof(Matriz));\n",
        "    m->filas = filas;\n",
        "    m->columnas = columnas;\n",
        "    m->datos = (float *)malloc(filas * columnas * sizeof(float));\n",
        "    return m;\n",
        "}\n",
        "\n",
        "#pragma endregion\n",
        "\n",
        "#pragma region KERNEL CUDA\n",
        "// [CUDA]El Kernel: Esta función corre DENTRO de la tarjeta gráfica\n",
        "// Calcula C = A * B. Cada hilo calcula UN solo píxel de la matriz resultado.\n",
        "__global__ void matmul_kernel(float *A, float *B, float *C, int rowsA, int colsA, int colsB)\n",
        "{\n",
        "    // Calculamos fila y columna global basándonos en el índice del hilo y del bloque\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Verificamos límites para no escribir fuera de memoria\n",
        "    if (row < rowsA && col < colsB)\n",
        "    {\n",
        "        float sum = 0.0f;\n",
        "        // Producto punto: Fila de A contra Columna de B\n",
        "        for (int k = 0; k < colsA; k++)\n",
        "        {\n",
        "            sum += A[row * colsA + k] * B[k * colsB + col];\n",
        "        }\n",
        "        C[row * colsB + col] = sum;\n",
        "    }\n",
        "}\n",
        "#pragma endregion\n",
        "\n",
        "#pragma region Manipular Matrices\n",
        "\n",
        "// Liberar la memoria ocupada por una matriz\n",
        "void liberar_matriz(Matriz *m)\n",
        "{\n",
        "    if (m)\n",
        "    {\n",
        "        if (m->datos)\n",
        "            free(m->datos);\n",
        "        free(m);\n",
        "    }\n",
        "}\n",
        "\n",
        "// Inicializar una matriz con valores aleatorios entre -0.5 y 0.5\n",
        "void inicializar_matriz_aleatoria(Matriz *m)\n",
        "{\n",
        "    for (int i = 0; i < m->filas * m->columnas; i++)\n",
        "    {\n",
        "        m->datos[i] = ((float)rand() / RAND_MAX) - 0.5f; // Valores entre -0.5 y 0.5\n",
        "    }\n",
        "}\n",
        "\n",
        "// Llenar una matriz con limpiar_matriz\n",
        "void limpiar_matriz(Matriz *m)\n",
        "{\n",
        "    memset(m->datos, 0, m->filas * m->columnas * sizeof(float));\n",
        "}\n",
        "\n",
        "// Multiplicar dos matrices A y B, almacenar el resultado en C\n",
        "// Se encarga de la logística: CPU -> GPU -> Kernel -> CPU\n",
        "void multiplicar_matrices(Matriz *A, Matriz *B, Matriz *C)\n",
        "{\n",
        "    if (A->columnas != B->filas)\n",
        "    {\n",
        "        printf(\"Error: dimensiones no compatibles.\\n\");\n",
        "        exit(1);\n",
        "    }\n",
        "\n",
        "    // Calcular tamaños en bytes\n",
        "    size_t size_A = A->filas * A->columnas * sizeof(float);\n",
        "    size_t size_B = B->filas * B->columnas * sizeof(float);\n",
        "    size_t size_C = C->filas * C->columnas * sizeof(float);\n",
        "\n",
        "    // Punteros para memoria en GPU\n",
        "    float *d_A, *d_B, *d_C;\n",
        "\n",
        "    // Reservar memoria en la GPU (cudaMalloc)\n",
        "    cudaMalloc((void**)&d_A, size_A);\n",
        "    cudaMalloc((void**)&d_B, size_B);\n",
        "    cudaMalloc((void**)&d_C, size_C);\n",
        "\n",
        "    // Copiar datos de la RAM a la VRAM\n",
        "    cudaMemcpy(d_A, A->datos, size_A, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, B->datos, size_B, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Configurar la cuadrícula de hilos\n",
        "    // Bloques de 16x16 hilos\n",
        "    dim3 threadsPerBlock(16, 16);\n",
        "    // Calculamos cuántos bloques necesitamos (redondeando hacia arriba)\n",
        "    dim3 blocksPerGrid((C->columnas + 15) / 16, (C->filas + 15) / 16);\n",
        "\n",
        "    //LANZAR EL KERNEL\n",
        "    matmul_kernel<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, A->filas, A->columnas, B->columnas);\n",
        "\n",
        "    // Esperar a que la GPU termine\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    //Copiar resultados de vuelta a la CPU\n",
        "    cudaMemcpy(C->datos, d_C, size_C, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    //Liberar memoria de GPU\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "}\n",
        "\n",
        "// Calcular la transpuesta de una matriz A y almacenarla en B\n",
        "// Asume que B ya ha sido inicializada con las dimensiones correctas (Dimensiones invertidas de A)\n",
        "// Se utiliza para la propagación hacia atrás en redes neuronales: dW = A^T * dZ\n",
        "void transpuesta(Matriz *A, Matriz *B)\n",
        "{\n",
        "    for (int i = 0; i < A->filas; i++)\n",
        "    {\n",
        "        for (int j = 0; j < A->columnas; j++)\n",
        "        {\n",
        "            // La fila i, col j de A pasa a ser la fila j, col i de B\n",
        "            B->datos[j * B->columnas + i] = A->datos[i * A->columnas + j];\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "void sumar_sesgo(Matriz *m, Matriz *b)\n",
        "{\n",
        "    for (int i = 0; i < m->filas; i++)\n",
        "    {\n",
        "        for (int j = 0; j < m->columnas; j++)\n",
        "        {\n",
        "            m->datos[i * m->columnas + j] += b->datos[j];\n",
        "        }\n",
        "    }\n",
        "}\n",
        "// Multiplicar una matriz por un escalar\n",
        "void multiplicar_escalar(Matriz *m, float escalar)\n",
        "{\n",
        "    for (int i = 0; i < m->filas * m->columnas; i++)\n",
        "    {\n",
        "        m->datos[i] *= escalar;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Restar matrices A = A - B\n",
        "void restar_matrices(Matriz *A, Matriz *B)\n",
        "{\n",
        "    for (int i = 0; i < A->filas * A->columnas; i++)\n",
        "    {\n",
        "        A->datos[i] -= B->datos[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "#pragma endregion\n",
        "\n",
        "#pragma region Funciones Auxiliares\n",
        "\n",
        "// Función de activación ReLU: Si x < 0, devuelve 0; si x >= 0, devuelve x\n",
        "void relu(Matriz *m)\n",
        "{\n",
        "    for (int i = 0; i < m->filas * m->columnas; i++)\n",
        "    {\n",
        "        if (m->datos[i] < 0)\n",
        "            m->datos[i] = 0;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Softmax: Convierte números en probabilidades\n",
        "void softmax(Matriz *m)\n",
        "{\n",
        "    for (int i = 0; i < m->filas; i++)\n",
        "    {\n",
        "        // Buscar máximo de la fila (estabilidad numérica)\n",
        "        float max_val = -1e9;\n",
        "        for (int j = 0; j < m->columnas; j++)\n",
        "        {\n",
        "            if (m->datos[i * m->columnas + j] > max_val)\n",
        "                max_val = m->datos[i * m->columnas + j];\n",
        "        }\n",
        "        // Exponencial y suma\n",
        "        float sum = 0.0f;\n",
        "        for (int j = 0; j < m->columnas; j++)\n",
        "        {\n",
        "            m->datos[i * m->columnas + j] = expf(m->datos[i * m->columnas + j] - max_val);\n",
        "            sum += m->datos[i * m->columnas + j];\n",
        "        }\n",
        "        // Normalizar para obtener probabilidades\n",
        "        for (int j = 0; j < m->columnas; j++)\n",
        "        {\n",
        "            m->datos[i * m->columnas + j] /= sum;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// Encuentra el índice del valor más alto (Argmax)\n",
        "// Ej: Si la salida es [0.1, 0.8, 0.1], devuelve 1.\n",
        "int argmax(Matriz *m, int row)\n",
        "{\n",
        "    float max_val = -1e9;\n",
        "    int max_index = 0;\n",
        "    for (int j = 0; j < m->columnas; j++)\n",
        "    {\n",
        "        if (m->datos[row * m->columnas + j] > max_val)\n",
        "        {\n",
        "            max_val = m->datos[row * m->columnas + j];\n",
        "            max_index = j;\n",
        "        }\n",
        "    }\n",
        "    return max_index;\n",
        "}\n",
        "\n",
        "#pragma endregion\n",
        "\n",
        "#pragma region Cargar Datos\n",
        "\n",
        "// Convertir Bytes High Endian a Enteros\n",
        "int convertir_bytes_a_enteros(FILE *fp)\n",
        "{\n",
        "    unsigned char buf[4];\n",
        "    if (fread(buf, sizeof(unsigned char), 4, fp) != 4)\n",
        "        return 0;\n",
        "    return (buf[0] << 24) | (buf[1] << 16) | (buf[2] << 8) | buf[3];\n",
        "}\n",
        "\n",
        "Matriz *cargar_imagenes_dataset(const char *filename)\n",
        "{\n",
        "    FILE *fp = fopen(filename, \"rb\");\n",
        "    if (!fp)\n",
        "    {\n",
        "        printf(\"Error abriendo %s\\n\", filename);\n",
        "        exit(1);\n",
        "    }\n",
        "\n",
        "    convertir_bytes_a_enteros(fp);\n",
        "    int num_imgs = convertir_bytes_a_enteros(fp);\n",
        "    int rows = convertir_bytes_a_enteros(fp);\n",
        "    int cols = convertir_bytes_a_enteros(fp);\n",
        "\n",
        "    Matriz *m = crear_matriz(num_imgs, rows * cols);\n",
        "    unsigned char temp;\n",
        "    for (int i = 0; i < m->filas * m->columnas; i++)\n",
        "    {\n",
        "        // Leer un byte por píxel\n",
        "        fread(&temp, sizeof(unsigned char), 1, fp);\n",
        "        // División por 255 para normalizar valores entre 0 y 1\n",
        "        m->datos[i] = (float)temp / 255.0f;\n",
        "    }\n",
        "    fclose(fp);\n",
        "    return m;\n",
        "}\n",
        "\n",
        "Matriz *cargar_etiquetas_dataset(const char *filename)\n",
        "{\n",
        "    FILE *fp = fopen(filename, \"rb\");\n",
        "    if (!fp)\n",
        "    {\n",
        "        printf(\"Error abriendo %s\\n\", filename);\n",
        "        exit(1);\n",
        "    }\n",
        "\n",
        "    convertir_bytes_a_enteros(fp);\n",
        "    int num_items = convertir_bytes_a_enteros(fp);\n",
        "\n",
        "    Matriz *m = crear_matriz(num_items, 1);\n",
        "    unsigned char temp;\n",
        "    for (int i = 0; i < num_items; i++)\n",
        "    {\n",
        "        fread(&temp, sizeof(unsigned char), 1, fp);\n",
        "        m->datos[i] = (float)temp;\n",
        "    }\n",
        "    fclose(fp);\n",
        "    return m;\n",
        "}\n",
        "\n",
        "#pragma endregion\n",
        "\n",
        "#pragma region Entrenamiento\n",
        "\n",
        "int main()\n",
        "{\n",
        "    srand(time(NULL)); // Semilla para números aleatorios\n",
        "\n",
        "    const int TAMAÑO_ENTRADA = 784; // 28x28 píxeles\n",
        "    const int TAMAÑO_CAPA_OCULTA = 512;\n",
        "    const int TAMAÑO_SALIDA = 10; // Dígitos 0-9\n",
        "    const float TASA_APRENDIZAJE = 0.01f;\n",
        "    const int EPOCAS = 10;\n",
        "    const int TAMAÑO_BATCH = 64;\n",
        "\n",
        "    printf(\"Cargando datos...\\n\");\n",
        "    Matriz *X_train = cargar_imagenes_dataset(\"./Resources/train-images.idx3-ubyte\");\n",
        "    Matriz *Y_train = cargar_etiquetas_dataset(\"./Resources/train-labels.idx1-ubyte\");\n",
        "    printf(\"Entrenamiento: %d imagenes cargadas.\\n\", X_train->filas);\n",
        "\n",
        "    // Inicializar pesos y sesgos\n",
        "    Matriz *W1 = crear_matriz(TAMAÑO_ENTRADA, TAMAÑO_CAPA_OCULTA);\n",
        "    inicializar_matriz_aleatoria(W1);\n",
        "    Matriz *b1 = crear_matriz(1, TAMAÑO_CAPA_OCULTA);\n",
        "    limpiar_matriz(b1);\n",
        "    Matriz *W2 = crear_matriz(TAMAÑO_CAPA_OCULTA, TAMAÑO_SALIDA);\n",
        "    inicializar_matriz_aleatoria(W2);\n",
        "    Matriz *b2 = crear_matriz(1, TAMAÑO_SALIDA);\n",
        "    limpiar_matriz(b2);\n",
        "\n",
        "    // Reservar memoria\n",
        "    Matriz *X_batch = crear_matriz(TAMAÑO_BATCH, TAMAÑO_ENTRADA);\n",
        "    Matriz *Y_batch = crear_matriz(TAMAÑO_BATCH, 1);\n",
        "\n",
        "    // Temporales de propagación hacia adelante\n",
        "    Matriz *Z1 = crear_matriz(TAMAÑO_BATCH, TAMAÑO_CAPA_OCULTA);\n",
        "    Matriz *A1 = crear_matriz(TAMAÑO_BATCH, TAMAÑO_CAPA_OCULTA);\n",
        "    Matriz *Z2 = crear_matriz(TAMAÑO_BATCH, TAMAÑO_SALIDA);\n",
        "    Matriz *A2 = crear_matriz(TAMAÑO_BATCH, TAMAÑO_SALIDA);\n",
        "\n",
        "    // Temporales de propagación hacia atrás\n",
        "    Matriz *dZ2 = crear_matriz(TAMAÑO_BATCH, TAMAÑO_SALIDA);\n",
        "    Matriz *dW2 = crear_matriz(TAMAÑO_CAPA_OCULTA, TAMAÑO_SALIDA);\n",
        "    Matriz *db2 = crear_matriz(1, TAMAÑO_SALIDA);\n",
        "    Matriz *A1_T = crear_matriz(TAMAÑO_CAPA_OCULTA, TAMAÑO_BATCH);\n",
        "\n",
        "    Matriz *dZ1 = crear_matriz(TAMAÑO_BATCH, TAMAÑO_CAPA_OCULTA);\n",
        "    Matriz *dW1 = crear_matriz(TAMAÑO_ENTRADA, TAMAÑO_CAPA_OCULTA);\n",
        "    Matriz *db1 = crear_matriz(1, TAMAÑO_CAPA_OCULTA);\n",
        "    Matriz *W2_T = crear_matriz(TAMAÑO_SALIDA, TAMAÑO_CAPA_OCULTA);\n",
        "    Matriz *X_batch_T = crear_matriz(TAMAÑO_ENTRADA, TAMAÑO_BATCH);\n",
        "\n",
        "    // Indices para mezclar datos\n",
        "    int *indices = (int *)malloc(X_train->filas * sizeof(int));\n",
        "    for (int k = 0; k < X_train->filas; k++)\n",
        "        indices[k] = k;\n",
        "\n",
        "    // Medición de tiempo\n",
        "    clock_t inicio_tiempo = clock();\n",
        "    // Bucle de entrenamiento\n",
        "    for (int epoca = 0; epoca < EPOCAS; epoca++)\n",
        "    {\n",
        "        // Mezclar datos al inicio de cada época\n",
        "        for (int k = X_train->filas - 1; k > 0; k--)\n",
        "        {\n",
        "            int j = rand() % (k + 1);\n",
        "            int temp = indices[k];\n",
        "            indices[k] = indices[j];\n",
        "            indices[j] = temp;\n",
        "        }\n",
        "\n",
        "        for (int i = 0; i < X_train->filas; i += TAMAÑO_BATCH)\n",
        "        {\n",
        "            int batch_actual = (i + TAMAÑO_BATCH > X_train->filas) ? X_train->filas - i : TAMAÑO_BATCH;\n",
        "            // Preparar Batch\n",
        "            for (int b = 0; b < batch_actual; b++)\n",
        "            {\n",
        "                int idx = indices[i + b];\n",
        "                memcpy(&X_batch->datos[b * TAMAÑO_ENTRADA], &X_train->datos[idx * TAMAÑO_ENTRADA], TAMAÑO_ENTRADA * sizeof(float));\n",
        "                Y_batch->datos[b] = Y_train->datos[idx];\n",
        "            }\n",
        "            // Ajustar tamaño lógico de matrices batch (por si el último es menor)\n",
        "            X_batch->filas = batch_actual;\n",
        "            Z1->filas = batch_actual;\n",
        "            A1->filas = batch_actual;\n",
        "            Z2->filas = batch_actual;\n",
        "            A2->filas = batch_actual;\n",
        "\n",
        "            // Propagación hacia adelante\n",
        "            multiplicar_matrices(X_batch, W1, Z1); //Llamado interno a CUDA\n",
        "            sumar_sesgo(Z1, b1);\n",
        "            memcpy(A1->datos, Z1->datos, batch_actual * TAMAÑO_CAPA_OCULTA * sizeof(float));\n",
        "            relu(A1);\n",
        "\n",
        "            multiplicar_matrices(A1, W2, Z2); //Llamado interno a CUDA\n",
        "            sumar_sesgo(Z2, b2);\n",
        "            memcpy(A2->datos, Z2->datos, batch_actual * TAMAÑO_SALIDA * sizeof(float));\n",
        "            softmax(A2);\n",
        "\n",
        "            // Propagación hacia atrás\n",
        "            // dZ2 = A2 - Y (one-hot)\n",
        "            memcpy(dZ2->datos, A2->datos, batch_actual * TAMAÑO_SALIDA * sizeof(float));\n",
        "            for (int b = 0; b < batch_actual; b++)\n",
        "            {\n",
        "                dZ2->datos[b * TAMAÑO_SALIDA + (int)Y_batch->datos[b]] -= 1.0f;\n",
        "            }\n",
        "\n",
        "            // Grads Capa 2\n",
        "            A1->filas = batch_actual; // Asegurar dim correcta\n",
        "            transpuesta(A1, A1_T);\n",
        "            multiplicar_matrices(A1_T, dZ2, dW2); //Llamado interno a CUDA\n",
        "            multiplicar_escalar(dW2, 1.0f / batch_actual);\n",
        "\n",
        "            limpiar_matriz(db2);\n",
        "            for (int r = 0; r < batch_actual; r++)\n",
        "            {\n",
        "                for (int c = 0; c < TAMAÑO_SALIDA; c++)\n",
        "                    db2->datos[c] += dZ2->datos[r * TAMAÑO_SALIDA + c];\n",
        "            }\n",
        "            multiplicar_escalar(db2, 1.0f / batch_actual);\n",
        "\n",
        "            // Error Capa 1\n",
        "            transpuesta(W2, W2_T);\n",
        "            multiplicar_matrices(dZ2, W2_T, dZ1); //Llamado interno a CUDA\n",
        "            for (int k = 0; k < batch_actual * TAMAÑO_CAPA_OCULTA; k++)\n",
        "            {\n",
        "                if (Z1->datos[k] <= 0)\n",
        "                    dZ1->datos[k] = 0.0f; // Derivada ReLU\n",
        "            }\n",
        "\n",
        "            // Grads Capa 1\n",
        "            X_batch->filas = batch_actual;\n",
        "            transpuesta(X_batch, X_batch_T);\n",
        "            multiplicar_matrices(X_batch_T, dZ1, dW1);\n",
        "            multiplicar_escalar(dW1, 1.0f / batch_actual);\n",
        "\n",
        "            limpiar_matriz(db1);\n",
        "            for (int r = 0; r < batch_actual; r++)\n",
        "            {\n",
        "                for (int c = 0; c < TAMAÑO_CAPA_OCULTA; c++)\n",
        "                    db1->datos[c] += dZ1->datos[r * TAMAÑO_CAPA_OCULTA + c];\n",
        "            }\n",
        "            multiplicar_escalar(db1, 1.0f / batch_actual);\n",
        "\n",
        "            // Actualizar parámetros\n",
        "            multiplicar_escalar(dW1, TASA_APRENDIZAJE);\n",
        "            restar_matrices(W1, dW1);\n",
        "            multiplicar_escalar(db1, TASA_APRENDIZAJE);\n",
        "            restar_matrices(b1, db1);\n",
        "            multiplicar_escalar(dW2, TASA_APRENDIZAJE);\n",
        "            restar_matrices(W2, dW2);\n",
        "            multiplicar_escalar(db2, TASA_APRENDIZAJE);\n",
        "            restar_matrices(b2, db2);\n",
        "        }\n",
        "        printf(\"Epoca %d completada.\\n\", epoca + 1);\n",
        "    }\n",
        "#pragma endregion\n",
        "#pragma region Evaluación\n",
        "    double total_time = (double)(clock() - inicio_tiempo) / CLOCKS_PER_SEC;\n",
        "    printf(\"Entrenamiento C finalizado en %.2f segundos.\\n\", total_time);\n",
        "\n",
        "#pragma endregion\n",
        "\n",
        "#pragma region Limpiar Memoria\n",
        "    free(indices);\n",
        "    liberar_matriz(X_train);\n",
        "    liberar_matriz(Y_train);\n",
        "    liberar_matriz(W1);\n",
        "    liberar_matriz(b1);\n",
        "    liberar_matriz(W2);\n",
        "    liberar_matriz(b2);\n",
        "    liberar_matriz(X_batch);\n",
        "    liberar_matriz(Y_batch);\n",
        "    liberar_matriz(Z1);\n",
        "    liberar_matriz(A1);\n",
        "    liberar_matriz(Z2);\n",
        "    liberar_matriz(A2);\n",
        "    liberar_matriz(dZ2);\n",
        "    liberar_matriz(dW2);\n",
        "    liberar_matriz(db2);\n",
        "    liberar_matriz(A1_T);\n",
        "    liberar_matriz(dZ1);\n",
        "    liberar_matriz(dW1);\n",
        "    liberar_matriz(db1);\n",
        "    liberar_matriz(W2_T);\n",
        "    liberar_matriz(X_batch_T);\n",
        "#pragma endregion\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "#pragma region Ejecución\n",
        "// Ejecutar con:\n",
        "// gcc mainB.c -o mlp -lm -O3\n",
        "// ./mlp\n",
        "#pragma endregion"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compilación y ejecución del archivo"
      ],
      "metadata": {
        "id": "GJCDyR-DI6s7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc mainA.cu -o mlp_cuda -lm -O3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-kOiOWRI_py",
        "outputId": "d9d228b5-b75a-4627-f48a-d169f139b6dd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01mmainA.cu(260)\u001b[0m: \u001b[01;35mwarning\u001b[0m #1650-D: result of call is not used\n",
            "          fread(&temp, sizeof(unsigned char), 1, fp);\n",
            "          ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mmainA.cu(284)\u001b[0m: \u001b[01;35mwarning\u001b[0m #1650-D: result of call is not used\n",
            "          fread(&temp, sizeof(unsigned char), 1, fp);\n",
            "          ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mmainA.cu(260)\u001b[0m: \u001b[01;35mwarning\u001b[0m #1650-D: result of call is not used\n",
            "          fread(&temp, sizeof(unsigned char), 1, fp);\n",
            "          ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mmainA.cu(284)\u001b[0m: \u001b[01;35mwarning\u001b[0m #1650-D: result of call is not used\n",
            "          fread(&temp, sizeof(unsigned char), 1, fp);\n",
            "          ^\n",
            "\n",
            "\u001b[01m\u001b[KmainA.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KMatriz* cargar_imagenes_dataset(const char*)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[KmainA.cu:260:6:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Ksize_t fread(void*, size_t, size_t, FILE*)\u001b[m\u001b[K’ declared with attribute ‘\u001b[01m\u001b[Kwarn_unused_result\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-result\u0007-Wunused-result\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  260 | \u001b[01;35m\u001b[K        fread(&temp, sizeof(unsigned char)\u001b[m\u001b[K, 1, fp);\n",
            "      |      \u001b[01;35m\u001b[K^\u001b[m\u001b[K  \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[KmainA.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KMatriz* cargar_etiquetas_dataset(const char*)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[KmainA.cu:284:6:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Ksize_t fread(void*, size_t, size_t, FILE*)\u001b[m\u001b[K’ declared with attribute ‘\u001b[01m\u001b[Kwarn_unused_result\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-result\u0007-Wunused-result\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  284 | \u001b[01;35m\u001b[K        fread(&temp, sizeof(unsigned char)\u001b[m\u001b[K, 1, fp);\n",
            "      |      \u001b[01;35m\u001b[K^\u001b[m\u001b[K  \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./mlp_cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiDN6EY3JlYM",
        "outputId": "2a974e03-c2eb-4978-ebea-8b7f2b6037cd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando datos...\n",
            "Entrenamiento: 60000 imagenes cargadas.\n",
            "Epoca 1 completada.\n",
            "Epoca 2 completada.\n",
            "Epoca 3 completada.\n",
            "Epoca 4 completada.\n",
            "Epoca 5 completada.\n",
            "Epoca 6 completada.\n",
            "Epoca 7 completada.\n",
            "Epoca 8 completada.\n",
            "Epoca 9 completada.\n",
            "Epoca 10 completada.\n",
            "Entrenamiento C finalizado en 25.42 segundos.\n"
          ]
        }
      ]
    }
  ]
}